# SafeServe AI - Enhanced Customer Assistant ğŸ›¡ï¸

A production-ready AI-powered customer service assistant with advanced fraud detection, multilingual support, and voice interaction capabilities.

## ğŸŒŸ Features

### Core Capabilities
- **Conversational Fraud Detection**: Real-time analysis of customer interactions using behavioral patterns and linguistic cues
- **Multilingual Support**: Support for English, Hindi, Tamil, Telugu, Bengali, Marathi, and Gujarati with automatic language detection
- **Voice Interaction**: Speech-to-text input and text-to-speech responses (with appropriate model setup)
- **Intelligent Responses**: Context-aware customer service responses powered by LLM integration
- **Real-time Analytics**: Comprehensive monitoring and reporting dashboard

### Security Features
- **Risk Scoring**: Dynamic fraud likelihood assessment with contextual analysis
- **Behavioral Analysis**: Pattern recognition for suspicious activities
- **Multi-factor Detection**: Combines urgency, request patterns, and linguistic indicators
- **User Profiling**: Conversation history analysis for improved accuracy

### Technical Features
- **RESTful API**: Production-ready FastAPI backend with comprehensive endpoints
- **Real-time Processing**: Efficient async processing with sub-second response times
- **Scalable Architecture**: Modular design for easy deployment and maintenance
- **Comprehensive UI**: Feature-rich Streamlit interface for testing and monitoring

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- pip package manager
- (Optional) GPU support for faster model inference

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd Intelligent_virtual_assistance_for_customer_service_with_fraud_detection
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   Create a `.env` file in the project root:
   ```env
   # API Configuration
   API_HOST=0.0.0.0
   API_PORT=8080
   DEBUG=false
   
   # LLM Configuration
   LLM_API_URL=http://localhost:8000/chat
   LLM_MODEL_NAME=llama2-7b-chat
   
   # Voice Configuration (optional)
   VOICE_CACHE_DIR=./voice_cache
   ENABLE_VOICE_RECOGNITION=false
   ENABLE_VOICE_SYNTHESIS=false
   
   # Fraud Detection Configuration
   FRAUD_THRESHOLD_HIGH=0.7
   FRAUD_THRESHOLD_SUSPICIOUS=0.4
   MAX_CONTEXT_LENGTH=5
   ```

4. **Start the API server**
   ```bash
   python backend/api.py
   ```

5. **Launch the UI (in a new terminal)**
   ```bash
   streamlit run ui/app.py
   ```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py                 # Main FastAPI application
â”‚   â”œâ”€â”€ logic/
â”‚   â”‚   â”œâ”€â”€ behavioral_fraud.py    # Fraud detection engine
â”‚   â”‚   â”œâ”€â”€ llm_chat.py            # LLM integration
â”‚   â”‚   â””â”€â”€ translator.py          # Multilingual support
â”‚   â””â”€â”€ safeserve_ai.py            # Legacy compatibility
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py                 # Streamlit interface
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ load_env.py            # Environment configuration
â”‚   â”œâ”€â”€ transaction_loader.py  # Transaction data utilities
â”‚   â””â”€â”€ voice_utils.py         # Voice processing utilities
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ serve_llm.ipynb        # LLM testing notebook
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸ”§ API Endpoints

### Main Assistant Endpoint
- **POST /assistant**
  - Unified endpoint for all interactions
  - Supports text and voice input
  - Returns fraud analysis and multilingual responses

### Health and Monitoring
- **GET /health** - System health check
- **GET /capabilities** - Available features and models
- **GET /user/{user_id}/summary** - User interaction summary

### Utility Endpoints
- **GET /** - API information and documentation
- **DELETE /user/{user_id}/conversation** - Clear conversation history

## ğŸ¯ Usage Examples

### Basic Text Interaction
```python
import requests

response = requests.post("http://localhost:8080/assistant", json={
    "text": "I need to check my account balance",
    "lang": "auto",
    "mode": "text",
    "user_id": "customer_123"
})

print(response.json())
```

### Multilingual Support
```python
# Hindi input
response = requests.post("http://localhost:8080/assistant", json={
    "text": "à¤®à¥à¤à¥‡ à¤…à¤ªà¤¨à¥‡ à¤–à¤¾à¤¤à¥‡ à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤šà¤¾à¤¹à¤¿à¤",
    "lang": "hi",
    "mode": "text",
    "user_id": "customer_123"
})
```

### Voice Interaction
```python
# Voice input (requires audio file)
with open("audio.wav", "rb") as f:
    audio_base64 = base64.b64encode(f.read()).decode()

response = requests.post("http://localhost:8080/assistant", json={
    "text": "[Voice Input]",
    "mode": "voice",
    "audio": audio_base64,
    "user_id": "customer_123"
})
```

## ğŸ›¡ï¸ Fraud Detection

### Risk Levels
- **Safe** (0.0-0.4): Normal customer interactions
- **Suspicious** (0.4-0.7): Requires additional verification
- **High Risk** (0.7-1.0): Potential fraud, immediate attention required

### Detection Features
- **Urgency Analysis**: Detects time-pressure tactics
- **Request Pattern Analysis**: Identifies unusual transaction patterns
- **Linguistic Cues**: Analyzes language for fraud indicators
- **Behavioral Consistency**: Compares with historical interactions

## ğŸŒ Multilingual Support

### Supported Languages
- English (en)
- Hindi (hi)
- Tamil (ta)
- Telugu (te)
- Bengali (bn)
- Marathi (mr)
- Gujarati (gu)

### Features
- **Automatic Language Detection**: Identifies input language
- **Bidirectional Translation**: Maintains context across languages
- **Native Script Support**: Handles Devanagari, Tamil, and other scripts
- **Cultural Context**: Considers cultural nuances in responses

## ğŸ¤ Voice Integration

### Setup Requirements
1. **Install voice dependencies**
   ```bash
   pip install vosk soundfile TTS
   ```

2. **Download language models**
   ```bash
   # Download Vosk models for speech recognition
   wget https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip
   # Extract and place in ./models/vosk/
   ```

3. **Configure environment**
   ```env
   ENABLE_VOICE_RECOGNITION=true
   ENABLE_VOICE_SYNTHESIS=true
   VOICE_CACHE_DIR=./voice_cache
   ```

## ğŸ“Š Analytics Dashboard

### Available Metrics
- **Interaction Volume**: Total messages processed
- **Risk Distribution**: Fraud detection statistics
- **Language Usage**: Multilingual interaction patterns
- **Processing Performance**: Response time analytics
- **User Behavior**: Conversation flow analysis

### Access via UI
1. Launch Streamlit UI
2. Navigate to "Analytics" tab
3. View real-time metrics and charts

## ğŸ”’ Security Considerations

### Data Protection
- **No Data Persistence**: Conversations are session-based
- **Configurable Retention**: Adjustable conversation history length
- **Secure Communication**: HTTPS ready for production
- **Input Validation**: Comprehensive request validation

### Fraud Prevention
- **Real-time Analysis**: Immediate risk assessment
- **Context Awareness**: Historical pattern analysis
- **Escalation Protocols**: Automated alerting for high-risk interactions
- **Audit Trail**: Comprehensive logging for compliance

## ğŸ§ª Testing

### Unit Tests
```bash
pytest tests/
```

### Integration Testing
1. Use the Streamlit UI testing tab
2. Run predefined fraud scenarios
3. Test multilingual capabilities
4. Verify voice processing (if enabled)

### Performance Testing
```bash
# Load testing with multiple concurrent users
python scripts/load_test.py
```

## ğŸš€ Deployment

### Docker Deployment
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8080

CMD ["python", "backend/api.py"]
```

### Production Checklist
- [ ] Configure environment variables
- [ ] Set up HTTPS/TLS
- [ ] Configure rate limiting
- [ ] Set up monitoring and logging
- [ ] Configure backup and recovery
- [ ] Test fraud detection accuracy
- [ ] Validate multilingual performance

## ğŸ“ˆ Performance Optimization

### Model Optimization
- **CPU Optimization**: Optimized for CPU-only inference
- **Memory Management**: Efficient model loading and caching
- **Batch Processing**: Grouped inference for better throughput
- **Async Processing**: Non-blocking request handling

### Scaling Recommendations
- **Horizontal Scaling**: Multiple API instances behind load balancer
- **Database Integration**: Add persistent storage for production
- **Caching Layer**: Redis for conversation and model caching
- **CDN Integration**: For voice file delivery

## ğŸ› Troubleshooting

### Common Issues

#### API Connection Failed
```bash
# Check if API is running
curl http://localhost:8080/health

# Check logs
tail -f logs/app.log
```

#### Voice Processing Issues
```bash
# Verify voice dependencies
pip install vosk soundfile TTS

# Check model availability
ls -la models/vosk/
```

#### Translation Errors
```bash
# Verify language models
python -c "from transformers import pipeline; print(pipeline('translation', model='Helsinki-NLP/opus-mt-en-hi'))"
```

## ğŸ¤ Contributing

### Development Setup
1. Fork the repository
2. Create feature branch
3. Install development dependencies
4. Run tests before submitting PR

### Code Style
- Follow PEP 8 conventions
- Use type hints
- Add comprehensive docstrings
- Include unit tests for new features

## ğŸ“„ License

This project is licensed under the MIT License - see LICENSE file for details.

## ğŸ”— Links

- **Documentation**: [Link to detailed docs]
- **API Reference**: [Link to API docs]
- **Model Repository**: [Link to model downloads]
- **Support**: [Link to support channels]

## ğŸ“ Support

For technical support or questions:
- Create an issue in the repository
- Contact the development team
- Check the troubleshooting guide

---

**SafeServe AI v2.0** - Built with â¤ï¸ for secure customer interactions
