"""
SafeServe AI - LLM Chat Interface
Clean interface to communicate with external LLM (Deepseek/Mistral via ngrok)
"""

import requests
import json
import logging
from typing import Dict, Optional, Any
from dataclasses import dataclass
import time

# Try to import transformers for ALBERT fallback
try:
    from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ChatResponse:
    """Chat response structure"""
    response: str
    model_used: str
    processing_time: float
    success: bool
    fallback: bool = False
    error_message: Optional[str] = None

class ALBERTFallbackEngine:
    """
    ALBERT-based fallback engine for when remote LLM is unavailable
    """
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.classifier = None
        self.initialized = False
        
        # Initialize if transformers is available
        if TRANSFORMERS_AVAILABLE:
            try:
                self._initialize_albert()
            except Exception as e:
                logger.warning(f"Failed to initialize ALBERT fallback: {e}")
    
    def _initialize_albert(self):
        """Initialize ALBERT model for fallback responses"""
        try:
            logger.info("Initializing ALBERT fallback engine...")
            
            # Use a smaller, faster model for fallback
            model_name = "albert-base-v2"
            
            # Initialize tokenizer and model
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
            
            # Create classification pipeline
            self.classifier = pipeline(
                "text-classification",
                model=self.model,
                tokenizer=self.tokenizer,
                return_all_scores=True
            )
            
            self.initialized = True
            logger.info("ALBERT fallback engine initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize ALBERT: {e}")
            self.initialized = False
    
    def classify_intent(self, text: str) -> str:
        """Classify user intent using ALBERT"""
        if not self.initialized:
            return "general"
        
        try:
            # Define intent patterns
            intent_patterns = {
                "fraud_concern": ["fraud", "suspicious", "scam", "unauthorized", "security"],
                "account_inquiry": ["account", "balance", "statement", "transaction"],
                "dispute": ["dispute", "refund", "charge", "wrong", "incorrect"],
                "help": ["help", "support", "assistance", "question"],
                "greeting": ["hello", "hi", "hey", "good morning", "good afternoon"]
            }
            
            text_lower = text.lower()
            
            # Simple keyword matching for intent classification
            for intent, keywords in intent_patterns.items():
                if any(keyword in text_lower for keyword in keywords):
                    return intent
            
            return "general"
            
        except Exception as e:
            logger.error(f"Error in intent classification: {e}")
            return "general"
    
    def generate_response(self, query: str, intent: str = None) -> str:
        """Generate response based on intent"""
        if intent is None:
            intent = self.classify_intent(query)
        
        # Template responses based on intent
        responses = {
            "fraud_concern": [
                "I understand you have security concerns. Please contact our fraud department immediately at 1-800-FRAUD or visit your nearest branch. For immediate safety, monitor your accounts closely and report any unauthorized transactions.",
                "This sounds like a potential security issue. Please call our fraud hotline at 1-800-FRAUD right away. In the meantime, check your recent transactions and report anything suspicious.",
                "For your security, please contact our fraud team immediately. You can reach them at 1-800-FRAUD or through our secure messaging system. Please don't share any personal information online."
            ],
            "account_inquiry": [
                "For account inquiries, you can check your balance through our mobile app, online banking, or by calling our customer service line. If you need assistance with specific transactions, please have your account details ready.",
                "You can access your account information through our mobile app or online banking portal. For detailed assistance, please contact customer service with your account number ready.",
                "To help with your account inquiry, please use our mobile app or online banking. For personalized assistance, call our customer service line during business hours."
            ],
            "dispute": [
                "For transaction disputes or refund requests, please provide the transaction details including date, amount, and merchant. We typically process dispute requests within 3-5 business days.",
                "I can help you with transaction disputes. Please gather the transaction details (date, amount, merchant) and contact our dispute team. Most cases are resolved within 3-5 business days.",
                "To dispute a transaction, please have the transaction details ready and contact our dispute department. We'll investigate and typically respond within 5 business days."
            ],
            "help": [
                "I'm here to help! You can ask me about account inquiries, transaction issues, security concerns, or general banking questions. How can I assist you today?",
                "I'm SafeServe AI, your banking assistant. I can help with account questions, security concerns, transaction disputes, and general banking support. What do you need help with?",
                "I'm ready to assist you with your banking needs. I can help with account inquiries, fraud concerns, transaction disputes, and general support. What would you like to know?"
            ],
            "greeting": [
                "Hello! I'm SafeServe AI, your intelligent banking assistant. How can I help you today?",
                "Good day! I'm here to help with your banking and security needs. What can I assist you with?",
                "Hi there! I'm SafeServe AI, ready to help with your banking questions and concerns. How may I assist you?"
            ],
            "general": [
                "Thank you for contacting SafeServe AI. I'm currently running on backup systems, but I'm here to help with your banking and security needs. Please try rephrasing your question or contact our customer service team for immediate assistance.",
                "I'm here to help with your banking needs. While I'm running on limited systems, I can assist with account inquiries, security concerns, and general banking questions. How can I help you?",
                "I'm SafeServe AI, operating on backup systems. I can still help with basic banking questions, security concerns, and account inquiries. What do you need assistance with?"
            ]
        }
        
        # Select response based on intent
        if intent in responses:
            import random
            return random.choice(responses[intent])
        else:
            return responses["general"][0]
    
    def is_available(self) -> bool:
        """Check if ALBERT fallback is available"""
        return self.initialized and TRANSFORMERS_AVAILABLE

class LLMChatInterface:
    """
    Interface to communicate with external LLM services
    """
    
    def __init__(self, llm_api_url: str, timeout: int = 30):
        self.llm_api_url = llm_api_url
        self.timeout = timeout
        self.session = requests.Session()
        
        # Initialize ALBERT fallback
        self.albert_fallback = ALBERTFallbackEngine()
        
        # Customer service context
        self.system_context = """You are SafeServe AI, an intelligent customer service assistant specializing in banking and financial security. You help customers with:

- Account inquiries and support
- Transaction disputes and fraud concerns
- Security questions and verification
- General banking assistance
- Fraud prevention education

Guidelines:
- Be helpful, professional, and empathetic
- Provide clear, actionable advice
- If fraud is suspected, guide the customer to appropriate security measures
- Never ask for sensitive information like passwords or PINs
- Keep responses concise but informative
- Use a reassuring tone for security concerns"""
    
    def create_customer_service_prompt(self, user_query: str, context: str = "") -> str:
        """
        Create a specialized prompt for customer service
        
        Args:
            user_query: Customer's question or concern
            context: Additional context (previous conversation, user info)
            
        Returns:
            Formatted prompt for LLM
        """
        prompt = f"""{self.system_context}

{f"Previous context: {context}" if context else ""}

Customer: {user_query}

SafeServe AI:"""
        
        return prompt
    
    def chat(self, query: str, context: str = "", temperature: float = 0.7, max_length: int = 512) -> ChatResponse:
        """
        Send chat request to LLM with ALBERT fallback
        
        Args:
            query: User query
            context: Previous conversation context
            temperature: Response randomness (0.0-1.0)
            max_length: Maximum response length
            
        Returns:
            ChatResponse object
        """
        start_time = time.time()
        
        try:
            # Create customer service prompt
            prompt = self.create_customer_service_prompt(query, context)
            
            # Prepare request
            request_data = {
                "query": prompt,
                "temperature": temperature,
                "max_length": max_length
            }
            
            # Make API request
            response = self.session.post(
                self.llm_api_url,
                json=request_data,
                timeout=self.timeout,
                headers={'Content-Type': 'application/json'}
            )
            
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                response_data = response.json()
                
                # Extract response text
                if "response" in response_data:
                    response_text = response_data["response"]
                    model_used = response_data.get("model_used", "unknown")
                    
                    # Clean up response
                    response_text = self._clean_response(response_text)
                    
                    return ChatResponse(
                        response=response_text,
                        model_used=model_used,
                        processing_time=processing_time,
                        success=True,
                        fallback=False
                    )
                else:
                    # Use ALBERT fallback for invalid response format
                    return self._use_albert_fallback(query, processing_time, "Invalid response format")
            else:
                # Use ALBERT fallback for API errors
                return self._use_albert_fallback(query, processing_time, f"API error: {response.status_code}")
                
        except requests.exceptions.Timeout:
            # Use ALBERT fallback for timeout
            processing_time = time.time() - start_time
            return self._use_albert_fallback(query, processing_time, "Request timeout")
            
        except requests.exceptions.ConnectionError:
            # Use ALBERT fallback for connection errors
            processing_time = time.time() - start_time
            return self._use_albert_fallback(query, processing_time, "Connection error")
            
        except Exception as e:
            # Use ALBERT fallback for any other errors
            processing_time = time.time() - start_time
            return self._use_albert_fallback(query, processing_time, f"Unexpected error: {str(e)}")
    
    def _use_albert_fallback(self, query: str, processing_time: float, error_message: str) -> ChatResponse:
        """Use ALBERT fallback when remote LLM fails"""
        logger.warning(f"Using ALBERT fallback due to: {error_message}")
        
        if self.albert_fallback.is_available():
            try:
                # Use ALBERT to generate response
                intent = self.albert_fallback.classify_intent(query)
                fallback_response = self.albert_fallback.generate_response(query, intent)
                
                return ChatResponse(
                    response=fallback_response,
                    model_used="albert-base-v2",
                    processing_time=processing_time,
                    success=True,
                    fallback=True,
                    error_message=error_message
                )
            except Exception as albert_error:
                logger.error(f"ALBERT fallback also failed: {albert_error}")
                return ChatResponse(
                    response=self._get_fallback_response(query),
                    model_used="template",
                    processing_time=processing_time,
                    success=False,
                    fallback=True,
                    error_message=f"Both LLM and ALBERT failed: {error_message}"
                )
        else:
            # Use template fallback if ALBERT is not available
            return ChatResponse(
                response=self._get_fallback_response(query),
                model_used="template",
                processing_time=processing_time,
                success=False,
                fallback=True,
                error_message=error_message
            )
    
    def _clean_response(self, response: str) -> str:
        """Clean and format the LLM response"""
        # Remove any system artifacts
        response = response.replace("SafeServe AI:", "").strip()
        response = response.replace("Assistant:", "").strip()
        
        # Remove extra whitespace
        response = " ".join(response.split())
        
        # Ensure proper sentence ending
        if response and not response.endswith(('.', '!', '?')):
            response += "."
        
        return response
    
    def _get_fallback_response(self, query: str) -> str:
        """Generate fallback response when LLM is unavailable"""
        query_lower = query.lower()
        
        # Simple keyword-based responses
        if any(word in query_lower for word in ['fraud', 'suspicious', 'scam', 'security']):
            return "I understand you have security concerns. Please contact our fraud department immediately at 1-800-FRAUD or visit your nearest branch. For immediate safety, monitor your accounts closely and report any unauthorized transactions."
        
        elif any(word in query_lower for word in ['account', 'balance', 'statement']):
            return "For account inquiries, you can check your balance through our mobile app, online banking, or by calling our customer service line. If you need assistance with specific transactions, please have your account details ready."
        
        elif any(word in query_lower for word in ['refund', 'dispute', 'transaction']):
            return "For transaction disputes or refund requests, please provide the transaction details including date, amount, and merchant. We typically process dispute requests within 3-5 business days."
        
        elif any(word in query_lower for word in ['help', 'support', 'assistance']):
            return "I'm here to help! You can ask me about account inquiries, transaction issues, security concerns, or general banking questions. How can I assist you today?"
        
        else:
            return "Thank you for contacting SafeServe AI. I'm currently experiencing technical difficulties, but I'm here to help with your banking and security needs. Please try rephrasing your question or contact our customer service team for immediate assistance."
    
    def health_check(self) -> bool:
        """Check if LLM service is available"""
        try:
            # Try to get health endpoint
            health_url = self.llm_api_url.replace('/chat', '/health')
            response = self.session.get(health_url, timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_service_info(self) -> Dict[str, Any]:
        """Get information about the LLM service"""
        try:
            # Try to get root endpoint
            root_url = self.llm_api_url.replace('/chat', '/')
            response = self.session.get(root_url, timeout=5)
            
            if response.status_code == 200:
                return response.json()
            else:
                return {"status": "unavailable", "error": f"HTTP {response.status_code}"}
        except Exception as e:
            return {"status": "unavailable", "error": str(e)}
    
    def get_fallback_info(self) -> Dict[str, Any]:
        """Get information about fallback capabilities"""
        return {
            "albert_available": self.albert_fallback.is_available(),
            "transformers_available": TRANSFORMERS_AVAILABLE,
            "fallback_model": "albert-base-v2" if self.albert_fallback.is_available() else "template"
        }

# Example usage
if __name__ == "__main__":
    # Initialize LLM interface
    llm_interface = LLMChatInterface("http://localhost:8000/chat")
    conversation_manager = ConversationManager()
    
    print("ü§ñ Testing LLM Chat Interface:")
    print("=" * 50)
    
    # Test health check
    health_status = llm_interface.health_check()
    print(f"Health Status: {'‚úÖ Online' if health_status else '‚ùå Offline'}")
    
    # Test service info
    service_info = llm_interface.get_service_info()
    print(f"Service Info: {service_info}")
    
    # Test conversation
    user_id = "test_user"
    test_queries = [
        "Hello, I need help with my account",
        "I noticed a suspicious transaction of $500 yesterday",
        "What should I do about this fraud?"
    ]
    
    print("\nüí¨ Testing Conversation:")
    print("-" * 30)
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{i}. Customer: {query}")
        
        # Add to conversation
        conversation_manager.add_message(user_id, query, is_user=True)
        
        # Get context
        context = conversation_manager.get_context(user_id)
        
        # Get response
        response = llm_interface.chat(query, context)
        
        # Add response to conversation
        conversation_manager.add_message(user_id, response.response, is_user=False)
        
        print(f"   SafeServe AI: {response.response}")
        print(f"   [Processing: {response.processing_time:.2f}s, Success: {response.success}]")
        
        if not response.success:
            print(f"   [Error: {response.error_message}]")
    
    # Show conversation summary
    summary = conversation_manager.get_conversation_summary(user_id)
    print(f"\nüìä Conversation Summary: {summary}")