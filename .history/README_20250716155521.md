# 🛡️ SafeServe AI - Intelligent Virtual Assistant for Customer Service with Fraud Detection

[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-green.svg)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28.1-red.svg)](https://streamlit.io)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

A production-ready AI virtual assistant system that combines real-time fraud detection with natural language customer support, powered by open-source technologies.

## 🎯 Features

- 🤖 **AI-Powered Chatbot**: Deepseek-Coder 6.7B model for intelligent customer service
- 🛡️ **Real-time Fraud Detection**: ML-based transaction analysis using Isolation Forest
- 📊 **Interactive Analytics**: Beautiful dashboards with transaction insights
- 🌐 **Multi-language Support**: Built-in language switching capability
- 🔧 **Microservices Architecture**: Clean separation of concerns
- 📱 **Responsive UI**: Modern Streamlit interface with custom styling
- 🚀 **Production Ready**: Comprehensive error handling and monitoring

## 🏗️ Architecture

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Streamlit UI  │───▶│   FastAPI API   │───▶│ Fraud Detection │
│     Frontend    │    │     Backend     │    │     Engine      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                │
                                ▼
                       ┌─────────────────┐
                       │ Deepseek LLM    │
                       │ (Google Colab)  │
                       └─────────────────┘
```

## 🚀 Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/safeserve-ai.git
cd safeserve-ai
```

### 2. Set Up Python Environment

```bash
# Create virtual environment
python -m venv safeserve-env

# Activate environment
# On Windows:
safeserve-env\Scripts\activate
# On macOS/Linux:
source safeserve-env/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Set Up the LLM Backend (Google Colab)

1. Open Google Colab in your browser
2. Upload and run the notebook: `notebooks/serve_llm.ipynb`
3. Set your ngrok token in the notebook
4. Copy the generated ngrok URL from the notebook output
5. Update the `.env` file with your ngrok URL

### 4. Configure Environment Variables

Edit the `.env` file with your settings:

```bash
# Get your ngrok token from https://ngrok.com/
NGROK_AUTH_TOKEN=your_actual_ngrok_token_here

# This will be generated by the Colab notebook
LLM_API_URL=https://your-ngrok-url.ngrok.io/chat

# API Configuration
API_HOST=0.0.0.0
API_PORT=8080
DEBUG=False
LOG_LEVEL=INFO
```

### 5. Start the Backend API

```bash
# From the root directory
cd backend
python api.py
```

The API will be available at `http://localhost:8080`

### 6. Launch the Frontend

```bash
# From the root directory
cd ui
streamlit run app.py
```

The UI will be available at `http://localhost:8501`

## 📁 Project Structure

```
SafeServe-AI/
├── backend/
│   ├── api.py                 # FastAPI main application
│   └── fraud_detection.py     # ML fraud detection engine
├── ui/
│   └── app.py                 # Streamlit frontend application
├── utils/
│   ├── load_env.py           # Environment configuration loader
│   └── transaction_loader.py # Transaction data processing
├── notebooks/
│   └── serve_llm.ipynb       # Google Colab LLM server
├── .env                      # Environment variables
├── requirements.txt          # Python dependencies
└── README.md                # This file
```

## 🔧 Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `NGROK_AUTH_TOKEN` | Your ngrok authentication token | Required |
| `LLM_API_URL` | URL of the LLM API endpoint | `http://localhost:8000/chat` |
| `API_HOST` | Backend API host | `0.0.0.0` |
| `API_PORT` | Backend API port | `8080` |
| `DEBUG` | Enable debug mode | `False` |
| `LOG_LEVEL` | Logging level | `INFO` |

### Fraud Detection Settings

The fraud detection engine uses the following features:
- Transaction amount
- Time of transaction (hour, day of week)
- Location risk score
- Device risk score
- Transaction velocity
- Merchant risk score

## 🛠️ API Endpoints

### Fraud Detection
- `POST /predict` - Analyze transaction for fraud
- `GET /transactions` - Get transaction history
- `GET /stats` - Get system statistics

### AI Chat
- `POST /chat` - Chat with AI assistant
- `GET /chats` - Get chat history

### Combined Analysis
- `POST /analyze-transaction-with-chat` - Fraud analysis with AI explanation

### System
- `GET /health` - Health check
- `GET /` - API information

## 📊 Usage Examples

### Fraud Detection API

```python
import requests

# Analyze a transaction
transaction_data = {
    "amount": 9000,
    "location": "foreign",
    "merchant": "online_shopping",
    "device_id": "unknown",
    "velocity_score": 5.0
}

response = requests.post(
    "http://localhost:8080/predict",
    json=transaction_data
)

result = response.json()
print(f"Risk Score: {result['risk_score']}")
print(f"Label: {result['label']}")
```

### Chat API

```python
import requests

# Chat with AI
chat_request = {
    "query": "What should I do if I suspect fraud?",
    "user_id": "user123"
}

response = requests.post(
    "http://localhost:8080/chat",
    json=chat_request
)

result = response.json()
print(f"AI Response: {result['response']}")
```

## 🧪 Testing

### Test Fraud Detection

```bash
# Test with sample transaction data
cd backend
python fraud_detection.py
```

### Test API Endpoints

```bash
# Install pytest
pip install pytest

# Run tests
pytest tests/
```

## 🔍 Monitoring & Debugging

### Check System Health

```bash
curl http://localhost:8080/health
```

### View Logs

The application logs are output to the console. Set `LOG_LEVEL=DEBUG` in `.env` for detailed logging.

### API Documentation

Once the backend is running, visit `http://localhost:8080/docs` for interactive API documentation.

## 🚨 Troubleshooting

### Common Issues

**1. LLM API Connection Failed**
- Ensure the Google Colab notebook is running
- Check that ngrok URL is correct in `.env`
- Verify ngrok token is valid

**2. Frontend Can't Connect to Backend**
- Ensure backend API is running on port 8080
- Check firewall settings
- Verify API_HOST and API_PORT in `.env`

**3. Fraud Detection Model Not Training**
- Check if required ML libraries are installed
- Ensure sufficient memory for model training
- Check Python version compatibility (3.8+)

**4. Missing Dependencies**
- Run `pip install -r requirements.txt` again
- Check for version conflicts
- Try creating a fresh virtual environment

## 📈 Performance Optimization

### For Production Deployment

1. **Use a dedicated GPU** for the LLM model
2. **Implement caching** for frequent queries
3. **Use a proper database** instead of in-memory storage
4. **Set up load balancing** for multiple API instances
5. **Implement proper logging** and monitoring

### Scaling Considerations

- **Horizontal scaling**: Deploy multiple API instances
- **Database optimization**: Use PostgreSQL or MongoDB
- **Model optimization**: Use quantized models for faster inference
- **Caching**: Implement Redis for response caching

## 🔐 Security

### Production Security Checklist

- [ ] Change default API keys and tokens
- [ ] Enable HTTPS for all endpoints
- [ ] Implement rate limiting
- [ ] Add authentication and authorization
- [ ] Sanitize all user inputs
- [ ] Use secrets management system
- [ ] Enable CORS properly
- [ ] Implement request validation

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- **Deepseek AI** for the open-source language model
- **FastAPI** for the excellent API framework
- **Streamlit** for the beautiful UI framework
- **scikit-learn** and **PyOD** for machine learning capabilities
- **ngrok** for tunneling solutions

## 📞 Support

For support, please open an issue on GitHub or contact the maintainers.

---

**⚡ Built with ❤️ for the open-source community**

*SafeServe AI - Protecting your transactions with artificial intelligence*
